{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat History\n",
    "\n",
    "Here we'll be interacting with a server that's exposing a chat bot with message history being persisted on the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "# set environment variables (in case different)\n",
    "os.environ['REDIS_OM_URL'] = \"redis://127.0.0.1:8001/0\"\n",
    "from svaeva_redux.schemas.redis import UserModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidResponse",
     "evalue": "Protocol error, got \"H\" as reply type byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m platform_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtelegram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[43mUserModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mUserModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis_om/model/model.py:1381\u001b[0m, in \u001b[0;36mRedisModel.find\u001b[0;34m(cls, knn, *expressions)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;241m*\u001b[39mexpressions: Union[Any, Expression],\n\u001b[1;32m   1379\u001b[0m     knn: Optional[KNNExpression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1380\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FindQuery:\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFindQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpressions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis_om/model/model.py:384\u001b[0m, in \u001b[0;36mFindQuery.__init__\u001b[0;34m(self, expressions, model, knn, offset, limit, page_size, sort_fields, nocontent)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     expressions: Sequence[ExpressionOrNegated],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     nocontent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ):\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhas_redisearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RedisModelError(\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Redis instance does not have either the RediSearch module \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor RedisJSON module installed. Querying requires that your Redis \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance has one of these modules installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpressions \u001b[38;5;241m=\u001b[39m expressions\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis_om/checks.py:25\u001b[0m, in \u001b[0;36mhas_redisearch\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     conn \u001b[38;5;241m=\u001b[39m get_redis_connection()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_redis_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     27\u001b[0m command_exists \u001b[38;5;241m=\u001b[39m check_for_command(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft.search\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis_om/checks.py:17\u001b[0m, in \u001b[0;36mhas_redis_json\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     conn \u001b[38;5;241m=\u001b[39m get_redis_connection()\n\u001b[0;32m---> 17\u001b[0m command_exists \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_for_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson.set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m command_exists\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis_om/checks.py:9\u001b[0m, in \u001b[0;36mcheck_for_command\u001b[0;34m(conn, cmd)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_for_command\u001b[39m(conn, cmd):\n\u001b[0;32m----> 9\u001b[0m     cmd_info \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cmd_info\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis/client.py:540\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m    538\u001b[0m pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_pool\n\u001b[1;32m    539\u001b[0m command_name \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 540\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_command_parse_response(\n\u001b[1;32m    545\u001b[0m             conn, command_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m    546\u001b[0m         ),\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disconnect_raise(conn, error),\n\u001b[1;32m    548\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis/connection.py:1104\u001b[0m, in \u001b[0;36mConnectionPool.get_connection\u001b[0;34m(self, command_name, *keys, **options)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_use_connections\u001b[38;5;241m.\u001b[39madd(connection)\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;66;03m# ensure this connection is connected to Redis\u001b[39;00m\n\u001b[0;32m-> 1104\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# connections that the pool provides should be ready to send\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# a command. if not, the connection was either returned to the\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# pool before all data has been read or the socket has been\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# closed. either way, reconnect and verify everything is good.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis/connection.py:288\u001b[0m, in \u001b[0;36mAbstractConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredis_connect_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;66;03m# Use the default on_connect function\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;66;03m# Use the passed function redis_connect_func\u001b[39;00m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredis_connect_func(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis/connection.py:391\u001b[0m, in \u001b[0;36mAbstractConnection.on_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlib_name:\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_command(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIENT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSETINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLIB-NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlib_name)\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ResponseError:\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis/connection.py:512\u001b[0m, in \u001b[0;36mAbstractConnection.read_response\u001b[0;34m(self, disable_decoding, disconnect_on_error, push_request)\u001b[0m\n\u001b[1;32m    508\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parser\u001b[38;5;241m.\u001b[39mread_response(\n\u001b[1;32m    509\u001b[0m             disable_decoding\u001b[38;5;241m=\u001b[39mdisable_decoding, push_request\u001b[38;5;241m=\u001b[39mpush_request\n\u001b[1;32m    510\u001b[0m         )\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisable_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_decoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m disconnect_on_error:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation--SnVyX7G-py3.11/lib/python3.11/site-packages/redis/_parsers/hiredis.py:128\u001b[0m, in \u001b[0;36m_HiredisParser.read_response\u001b[0;34m(self, disable_decoding)\u001b[0m\n\u001b[1;32m    126\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mgets(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# if the response is a ConnectionError or the response is a list and\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# the first item is a ConnectionError, raise it as something bad\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# happened\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;167;01mConnectionError\u001b[39;00m):\n",
      "\u001b[0;31mInvalidResponse\u001b[0m: Protocol error, got \"H\" as reply type byte"
     ]
    }
   ],
   "source": [
    "# get all UserModels that have recently interacted\n",
    "group_id = \"metamersion3-test0\"\n",
    "count = 0\n",
    "platform_id = \"telegram\"\n",
    "\n",
    "users = UserModel.find(\n",
    "            (UserModel.group_id == group_id)\n",
    "        ).all()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 1.0\n",
      "commit: commit\n",
      "id: Eric\n",
      "group_id: metamersion3\n",
      "platform_id: ipython\n",
      "interaction_count: 0\n",
      "first_name: None\n",
      "last_name: None\n",
      "username: None\n",
      "description: \n",
      "phone_number: None\n",
      "email: None\n",
      "register_method: None\n",
      "country: None\n",
      "age: None\n",
      "gender: None\n",
      "english_proficiency: None\n",
      "date_created_timestamp: 1709322541.066058\n",
      "date_updated_timestamp: 1709322541.066075\n",
      "date_accessed_timestamp: 1709470125.07686\n",
      "date_updated: 2024-03-01T19:49:01.066074\n",
      "date_accessed: 2024-03-03 12:48:45.076860\n"
     ]
    }
   ],
   "source": [
    "# client = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bejeweled_gifter(users, level: int):\n",
    "     # get all conversations from those users\n",
    "    for user in users:\n",
    "        print(user)\n",
    "        # conversation_id = 6070074875\n",
    "        # key = f\"message_store:{conversation_id}\"\n",
    "        # conversation = client.lrange(key, 0, -1)\n",
    "\n",
    "\n",
    "# get all users in group_id that fulfill the condition 0\n",
    "\n",
    "def conversation_image_gifting_condition_interactions(group_id: str, interaction_count: int) -> None:\n",
    "    \"\"\"Users who have not received a gift after n interactions\n",
    "\n",
    "    Args:\n",
    "        group_id (str): the group id of the users to include\n",
    "        interaction_count (int): the number of interactions to include\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    # find all users beloning in group_id with interaction_count = n\n",
    "    # users = client.smembers(f\"group:{group_id}:users\")\n",
    "\n",
    "    users = UserModel.find(\n",
    "            (UserModel.group_id == group_id) & \n",
    "            (UserModel.interaction_count == interaction_count) &\n",
    "            (UserModel.platform_id == \"telegram\")\n",
    "        )\n",
    "\n",
    "    if interaction_count == 0:\n",
    "        system_prompt = \"\" # level 0\n",
    "        bejeweled_gifter(users, level=0)\n",
    "\n",
    "    elif interaction_count == 5:\n",
    "        system_prompt = \"\" # level 1\n",
    "        bejeweled_gifter(users, level=1)\n",
    "\n",
    "\n",
    "\n",
    "conversation_image_gifting_condition_interactions(group_id=\"metamersion3\", interaction_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REDIS_OM_URL=redis://127.0.0.1:6379/0\n",
      "redis://127.0.0.1:6379/0\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/eric/Library/CloudStorage/Dropbox/git/github/svaeva_redux/svaeva_redux\")\n",
    "\n",
    "%env REDIS_OM_URL=redis://127.0.0.1:6379/0\n",
    "conversation_id = str(uuid.uuid4())\n",
    "user_id = \"Eric\"\n",
    "conversation_id = \"1234\"\n",
    "platform_id = \"ipython\"\n",
    "\n",
    "print(os.getenv(\"REDIS_OM_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"As an AI, I don't have the ability to keep track of our past interactions. I'm designed to respect user privacy and confidentiality. However, I'm here to help you with any questions or tasks you have now.\" id=None name=None\n"
     ]
    }
   ],
   "source": [
    "from svaeva_redux.schemas.redis import UserModel\n",
    "\n",
    "user = UserModel(id=user_id, group_id=\"metamersion3\", platform_id=platform_id)\n",
    "user.save()\n",
    "chat = RemoteRunnable(\"http://0.0.0.0:8000/\", cookies={\"user_id\": user_id})\n",
    "# chat.invoke(input={\"human_input\": \"my name is eugene. what is your name?\"})\n",
    "output = chat.invoke({\"human_input\": \"Count how many interactions we've had\"}, config={\"configurable\": {\"user_id\": user_id, \"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a prompt composed of a system message and a human message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.increment_interaction_count()\n",
    "user.interaction_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis_om import Migrator\n",
    "# Before running queries, we need to run migrations to set up the\n",
    "# indexes that Redis OM will use. You can also use the `migrate`\n",
    "# CLI tool for this!\n",
    "\n",
    "# redis_conn = redis.from_url(os.getenv(\"REDIS_OM_URL\"))\n",
    "# redis_conn = redis.from_url(\"redis://127.0.0.1:6379/0\")\n",
    "Migrator().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User not found\n"
     ]
    }
   ],
   "source": [
    "from redis_om import NotFoundError\n",
    "# get all users in the group\n",
    "\n",
    "try:\n",
    "    user = UserModel.get(\"asdasdasd\")\n",
    "except NotFoundError:\n",
    "    print(\"User not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eric 50\n",
      "[UserModel(version='1.0', commit='commit', id='Eric', group_id='metamersion3', platform_id='ipython', interaction_count=50, first_name=None, last_name=None, username=None, description='', phone_number=None, email=None, register_method=None, country=None, age=None, gender=None, english_proficiency=None, date_created_timestamp=1709222046.008508, date_updated_timestamp=1709222287.259773, date_accessed_timestamp=1709222365.882055, date_updated='2024-02-29T15:58:07.259772', date_accessed=datetime.datetime(2024, 2, 29, 15, 59, 25, 882062))]\n"
     ]
    }
   ],
   "source": [
    "from redis_om import NotFoundError\n",
    "try:\n",
    "    user = UserModel.get(user_id)\n",
    "except NotFoundError:\n",
    "    print(\"User not found\")\n",
    "\n",
    "\n",
    "# get all users with number of interactions greater than 1\n",
    "users = UserModel.find(\n",
    "        (UserModel.interaction_count >= 1) &\n",
    "        (UserModel.group_id == \"metamersion3\")\n",
    "    ).all()\n",
    "\n",
    "for user in users:\n",
    "    print(user.id, user.interaction_count)\n",
    "    # get conversations \n",
    "    \n",
    "\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svaeva_redux.langchain.redis import RedisChatMessageHistoryWindowed\n",
    "\n",
    "key_prefix = \"message_store:\"\n",
    "url = \"redis://127.0.0.1\"\n",
    "chat_history_length = 10\n",
    "\n",
    "def retrieve_redis_windowed_chat_history_as_text(session_id: str, url: str, key_prefix: str, chat_history_length: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the chat history from Redis and return it as a string formatted for ingestion\n",
    "\n",
    "\n",
    "    Args:\n",
    "        session_id (str): The session id.\n",
    "        url (str): The url of the Redis server.\n",
    "        key_prefix (str): The key prefix for the chat history.\n",
    "        chat_history_length (int): The length of the chat history.\n",
    "\n",
    "    Returns:\n",
    "        str: The chat history as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    history = RedisChatMessageHistoryWindowed(session_id=session_id, url=url, key_prefix=key_prefix, chat_history_length=chat_history_length)\n",
    "    conversation = \"\"\n",
    "    for message in history.messages:\n",
    "        if message.type == \"human\":\n",
    "            text = \"Human: \" + message.content\n",
    "        elif message.type == \"ai\":\n",
    "            text = \"AI: \" + message.content\n",
    "        conversation += text + \"\\n\"\n",
    "\n",
    "    return conversation\n",
    "\n",
    "\n",
    "conversation = retrieve_redis_windowed_chat_history_as_text(\n",
    "    session_id=conversation_id,\n",
    "    url=url,\n",
    "    key_prefix=key_prefix,\n",
    "    chat_history_length=chat_history_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'messages' of 'RedisChatMessageHistory' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m key_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_store:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m history \u001b[38;5;241m=\u001b[39m RedisChatMessageHistory(session_id\u001b[38;5;241m=\u001b[39muser_id, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredis://127.0.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_prefix\u001b[38;5;241m=\u001b[39mkey_prefix)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m \u001b[38;5;241m=\u001b[39m truncated_message_history\u001b[38;5;241m.\u001b[39mmessages\n",
      "\u001b[0;31mAttributeError\u001b[0m: property 'messages' of 'RedisChatMessageHistory' object has no setter"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import (\n",
    "    ChatMessageHistory,\n",
    "    RedisChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "truncated_message_history = ChatMessageHistory()\n",
    "key_prefix = \"message_store:\"\n",
    "history = RedisChatMessageHistory(session_id=user_id, url=\"redis://127.0.0.1\", key_prefix=key_prefix)\n",
    "history.messages = truncated_message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "redis_client = redis.StrictRedis(host=\"localhost\", port=6379, db=0)\n",
    "if not redis_client.exists(\":svaeva_redux.schemas.conversation.ConversationModel:default_0\"):\n",
    "    print(\"Database initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIConfig(BaseModel):\n",
    "    api_key: Optional[str] = None\n",
    "    engine: str = \"gpt-4\"\n",
    "    temperature: float = Field(0.7, ge=0.0, le=1.0)\n",
    "    max_tokens: int = Field(150, gt=0)\n",
    "    model_token_limit: int = Field(8192, gt=0)\n",
    "    top_p: float = Field(1.0, ge=0.0, le=1.0)\n",
    "    frequency_penalty: float = Field(0.0, ge=0.0)\n",
    "    presence_penalty: float = Field(0.0, ge=0.0)\n",
    "\n",
    "    @validator('api_key')\n",
    "    def api_key_must_be_provided(cls, v, values):\n",
    "        if v is None:\n",
    "            raise ValueError(\"API key must be provided.\")\n",
    "        return v\n",
    "\n",
    "    @validator('engine')\n",
    "    def engine_must_be_valid(cls, v):\n",
    "        valid_engines = [\"text-davinci-003\", \"text-davinci-004\", \"text-curie-003\"]  # Add more engines as needed\n",
    "        if v not in valid_engines:\n",
    "            raise ValueError(f\"Invalid engine '{v}'. Valid engines are: {', '.join(valid_engines)}\")\n",
    "        return v\n",
    "\n",
    "    @validator('temperature', 'top_p', 'frequency_penalty', 'presence_penalty')\n",
    "    def value_must_be_within_range(cls, v):\n",
    "        if v < 0 or v > 1:\n",
    "            raise ValueError(\"Value must be between 0 and 1.\")\n",
    "        return v\n",
    "\n",
    "    @validator('max_tokens')\n",
    "    def max_tokens_must_be_positive(cls, v):\n",
    "        if v <= 0:\n",
    "            raise ValueError(\"Max tokens must be a positive integer.\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from numpy import clip\n",
    "user_id = \"Eric\"\n",
    "REDIS_URL = \"redis://localhost:6379/0\"\n",
    "key_prefix = \"message_store:\"\n",
    "history = RedisChatMessageHistory(session_id=user_id, url=REDIS_URL, key_prefix=key_prefix)\n",
    "print(len(history.messages))\n",
    "\n",
    "# from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='my name is eugene. what is your name?'), AIMessage(content=\"Does it really matter? I mean, we're just talking here. No need for formalities.\")]\n"
     ]
    }
   ],
   "source": [
    "from regex import B\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# max sure max_length is even number\n",
    "max_length = 2\n",
    "if max_length % 2 != 0 and max_length > 0:\n",
    "    max_length -= 1\n",
    "\n",
    "message_history = ChatMessageHistory()\n",
    "for message in history.messages:\n",
    "    if len(message_history.messages) >= max_length:\n",
    "        break\n",
    "    # clipped_messages.append(message)\n",
    "    message_history.add_message(message)\n",
    "\n",
    "print(message_history.messages)\n",
    "# message_history.aadd_messages("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Eugene. How may I assist you today, Eugene?')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke({\"human_input\": \"What's my name?\"}, {\"configurable\": {\"conversation_id\": conversation_id, \"platform_id\": platform_id}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different user but same conversation id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = RemoteRunnable(\"http://localhost:8000/\", cookies={\"user_id\": \"nuno\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I apologize, but I don't have access to personal information like names.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke({\"human_input\": \"what was my name?\"}, {'configurable': { 'conversation_id': conversation_id }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Of\n",
      " course\n",
      "!\n",
      " Here\n",
      " you\n",
      " go\n",
      ":\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for chunk in chat.stream({'human_input': \"Can you count till 3?\"},  {'configurable': { 'conversation_id': conversation_id } }):\n",
    "    print()\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It sounds like you're describing an image that portrays a variety of people engaging in different activities, depicted in a minimalist and monochrome style. As an AI, I don't have the ability to see or perceive images, but I can understand and respond to your description. It seems like this image may evoke a sense of diversity, movement, and everyday life. If you have any specific questions or thoughts about the image, feel free to share, and I'll do my best to assist you further.\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "image_vlm = RemoteRunnable(\"http://localhost:8000/image_vlm\")\n",
    "# Read the audio file in binary mode\n",
    "with open('metamersion.png', 'rb') as image_file:\n",
    "    image_data = image_file.read()\n",
    "\n",
    "# Encode the audio data in Base64\n",
    "encoded_image_data = base64.b64encode(image_data).decode('utf-8')\n",
    "# chat.invoke({\"human_input\": \"What's my name?\"}, {\"configurable\": {\"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n",
    "image_vlm.invoke({\"image\": encoded_image_data, \"configurable\": {\"user_id\": user_id, \"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAHGZ0eX BDNjUpKQ==\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I can hear you loud and clear, Eugene! How can I assist you today?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "audio_stt = RemoteRunnable(\"http://localhost:8000/audio_stt\")\n",
    "# Read the audio file in binary mode\n",
    "with open('test.m4a', 'rb') as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "# Encode the audio data in Base64\n",
    "encoded_audio_data = base64.b64encode(audio_data).decode('utf-8')\n",
    "print(encoded_audio_data[0:10], encoded_audio_data[-10:])\n",
    "# chat.invoke({\"human_input\": \"What's my name?\"}, {\"configurable\": {\"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n",
    "audio_stt.invoke({\"audio\": encoded_audio_data, \"configurable\": {\"user_id\": user_id, \"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(data)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-app-Nf9Fhxwd-py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.pdf'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "with open(\"sample.pdf\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "encoded_data = base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "audio_stt.invoke({\"file\": encoded_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my name is eugene. what is your name?\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ai\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Hello Eugene! I'm Bob, your virtual assistant. How can I assist you today?\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ai\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"what was my name?\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ai\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Your name is Eugene. Is there something specific you would like assistance with, Eugene?\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ai\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cat chat_histories/eugene/cd8e5a55-0295-41cd-a885-775e0403fd25.json | jq ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"what was my name?\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ai\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"I apologize, but I don't have access to personal information about users. As an AI assistant, I prioritize user privacy and data protection.\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ai\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Can you count till 10?\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"AIMessageChunk\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"content\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Of course! Here you go:\\n\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"additional_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"AIMessageChunk\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"example\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cat chat_histories/nuno/cd8e5a55-0295-41cd-a885-775e0403fd25.json | jq ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
