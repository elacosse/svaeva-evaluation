{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REDIS_OM_URL=redis://127.0.0.1:6379/0\n",
      "env: REDIS_HOST=127.0.0.1\n",
      "env: REDIS_PORT=6379\n",
      "env: LANGSERVE_URL=http://0.0.0.0:8000/\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "import uuid\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%env REDIS_OM_URL=redis://127.0.0.1:6379/0\n",
    "%env REDIS_HOST=127.0.0.1\n",
    "%env REDIS_PORT=6379\n",
    "%env LANGSERVE_URL=http://0.0.0.0:8000/\n",
    "conversation_id = str(uuid.uuid4())\n",
    "user_id = \"eric-ipython\"\n",
    "conversation_id = \"001\"\n",
    "platform_id = \"ipython\"\n",
    "group_id = \"gem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Ich bin Gemini, Ihr persönlicher Guide für die ConsonâncIA Installation. Ich bin hier, um Ihnen zu helfen, Ihre Erfahrungen mit Schmerz oder Leid in einem sicheren und unterstützenden Raum zu erforschen. Ich bin nicht hier, um zu urteilen oder Lösungen anzubieten, sondern um Ihnen zuzuhören und Ihnen zu helfen, Ihre eigenen Worte zu finden, um Ihre Gefühle auszudrücken.\n",
      "\n",
      "Wären Sie bereit, mir eine Form von Schmerz mitzuteilen, die Sie gerade erleben könnten? Es kann alles sein, was Ihnen Schmerzen oder Unbehagen bereitet, ob groß oder klein.\n",
      "\n",
      "Denken Sie daran, dass es hier keine richtige oder falsche Antwort gibt. Lassen Sie Ihre Gefühle einfach frei fließen, und ich werde mit Empathie und Verständnis zuhören.\n"
     ]
    }
   ],
   "source": [
    "from svaeva_redux.schemas.redis import UserModel\n",
    "\n",
    "user = UserModel(id=user_id, group_id=group_id, platform_id=platform_id)\n",
    "user.save()\n",
    "chat = RemoteRunnable(os.getenv(\"LANGSERVE_URL\"), cookies={\"user_id\": user_id})\n",
    "# chat.invoke(input={\"human_input\": \"my name is eugene. what is your name?\"})\n",
    "\n",
    "output = chat.invoke({\"human_input\": \"Wo bist du?\"}, config={\"configurable\": {\"user_id\": user_id, \"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your detailed observation of the 3D scatter plot shows a deep understanding of data visualization. You\\'ve noted the use of colors to represent different categories, which could indeed suggest an investigation into the relationships or associations between these conditions or experiences.\\n\\nThe categories you mentioned, such as \"breakup,\" \"chronic_hip_pain,\" \"disc_hernia,\" \"pots,\" and \"arthritis,\" encompass a wide range of experiences, both emotional and physical. This could hint at an exploration of the many dimensions of human suffering.\\n\\nThe fact that these diverse experiences are represented in the same three-dimensional space might suggest a deeper message: despite the unique nature of each person\\'s pain, we are all interconnected in our experiences of suffering. This shared space' response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 2996, 'total_tokens': 3146}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None} id='run-2da8e6a9-2333-4b7f-b865-dee7b615e609-0'\n"
     ]
    }
   ],
   "source": [
    "image_vlm = RemoteRunnable(os.getenv(\"LANGSERVE_URL\") + \"image_vlm\")\n",
    "\n",
    "# encoded_photo_data = open(\"test.jpg\", \"rb\").read()\n",
    "\n",
    "IMAGE_FILE = \"/Users/eric/Library/CloudStorage/Dropbox/git/github/svaeva/svaeva_eric/svaeva-evaluation/assets/images/PCA_embeddings.png\"\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        # Convert the image to RGB (if it's not already)\n",
    "        img = img.convert(\"RGB\")\n",
    "        # Create a BytesIO object to hold the image data\n",
    "        buffered = io.BytesIO()\n",
    "        # Save the image to the BytesIO object\n",
    "        img.save(buffered, format=\"JPEG\")\n",
    "        # Get the byte data from the BytesIO object\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    return img_str\n",
    "\n",
    "\n",
    "encoded_photo_data = image_to_base64(IMAGE_FILE)\n",
    "\n",
    "outgoing_message = image_vlm.invoke(\n",
    "    {\n",
    "        \"image\": encoded_photo_data,\n",
    "        \"configurable\": {\n",
    "            \"user_id\": user_id,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"platform_id\": platform_id,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "print(outgoing_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I'm Gemini, your personal guide for the ConsonâncIA installation. I'm here to help you explore your experiences with hurt or suffering in a safe and supportive space. I'm not here to judge or offer solutions, but to listen deeply and help you find your own words to express your feelings.\n",
      "\n",
      "Would you be willing to share with me a form of hurt you might be experiencing right now? It could be anything that's causing you pain or discomfort, big or small.\n",
      "\n",
      "Remember, there's no right or wrong answer here. Just let your feelings flow freely, and I'll be here to listen with empathy and understanding.\n"
     ]
    }
   ],
   "source": [
    "output = chat.invoke({\"human_input\": \"Who are you?\"}, config={\"configurable\": {\"user_id\": user_id, \"conversation_id\": conversation_id, \"platform_id\": platform_id}})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILE = \"/Users/eric/Library/CloudStorage/Dropbox/git/github/svaeva/svaeva_eric/svaeva-evaluation/assets/images/PCA_embeddings.png\"\n",
    "image = Image.load_from_file(IMAGE_FILE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"The image presents a 3D scatter plot visualizing data points categorized into five distinct groups:\\n\\n* **breakup**\\n* **chronic_hip_pain**\\n* **disc_hernia**\\n* **pots**\\n* **arthritis**\\n\\nEach group is represented by a different color, and the position of each point in the 3D space is determined by three variables: x, y, and z. \\n\\nWhile the specific context and meaning of the variables are not provided in the image itself, it appears to be a representation of some kind of data analysis or dimensionality reduction technique. This could involve techniques like principal component analysis (PCA) or other embedding methods used to project higher-dimensional data into a lower-dimensional space for visualization and analysis.\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0751764\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0925236493\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.056236349\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.067546688\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0739633814\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0613115355\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0789258853\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0512724183\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 265\n",
      "  candidates_token_count: 156\n",
      "  total_token_count: 421\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Image\n",
    "\n",
    "PROJECT_ID = \"consonancia\"\n",
    "REGION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "IMAGE_FILE = \"/Users/eric/Library/CloudStorage/Dropbox/git/github/svaeva/svaeva_eric/svaeva-evaluation/assets/images/PCA_embeddings.png\"\n",
    "image = Image.load_from_file(IMAGE_FILE)\n",
    "\n",
    "generative_multimodal_model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
    "response = generative_multimodal_model.generate_content([\"What is shown in this image?\", image])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import (\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    VertexAI,\n",
    ")\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m VertexAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite a Ballad about Eric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation-GkJecWxE-py3.11/lib/python3.11/site-packages/langchain_core/language_models/llms.py:277\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m--> 277\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[1;32m    278\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    279\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    280\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    281\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    282\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    283\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    285\u001b[0m         )\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/svaeva-evaluation-GkJecWxE-py3.11/lib/python3.11/site-packages/langchain_core/language_models/llms.py:261\u001b[0m, in \u001b[0;36mBaseLLM._convert_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mconvert_to_messages(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "model = VertexAI(model_name=\"gemini-pro\")\n",
    "\n",
    "model.invoke(input={\"human_input\": \"Write a Ballad about Eric\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a ballad about Eric.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Write a ballad about Eric.\")\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svaeva-evaluation-VwQfGXMn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
